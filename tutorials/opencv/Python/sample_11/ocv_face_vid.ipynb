{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Tutorial Sample 11: ocv_face_vid\n",
    "\n",
    "[Sample 11](sample_11/ocv_face_vid.py) is a basic Face and Eye Detection program that uses OpenCV to analyze real-time video and detect human faces and eyes. The detected areas or Regions of Interest (ROI) are demarcated with rectangles. The program uses the OpenCV built-in pre-trained Haar feature-based cascade classifiers in order to perform this task.\n",
    "\n",
    "This sample uses the same basic procedures from the previous samples to detect faces and eyes in real-time video. The detection is performed on every video frame.\n",
    "\n",
    "The OS and SYS modules are also loaded in this sample in order to automatically locate the OpenCV libraries and use the Haar Cascade Classifier files.\n",
    "\n",
    "Here is the initialization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face and Eyes Tracker for Real-Time Video\n",
      "Type Esc to Exit Program ...\n",
      "C:\\opencv_pre\\\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "# Allows use of print like a function in Python 2.x\n",
    "\n",
    "# Import Python modules\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "print('Face and Eyes Tracker for Real-Time Video')\n",
    "print('Type Esc to Exit Program ...')\n",
    "try:\n",
    "    # Checks to see if OpenCV can be found\n",
    "    ocv = os.getenv(\"OPENCV_DIR\")\n",
    "    print(ocv)\n",
    "except KeyError:\n",
    "    print('Cannot find OpenCV')\n",
    "# This automatically locates the cascade files within OpenCV\n",
    "pri_cascade_file = os.path.join(ocv,'build\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "sec_cascade_file = os.path.join(ocv,'build\\etc\\haarcascades\\haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "# Uncomment for Debug if needed\n",
    "#print(pri_cascade_file)\n",
    "#print(sec_cascade_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the classifiers to use. We are still using the pre-trained classifiers provided as part of OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(pri_cascade_file)\n",
    "eye_cascade = cv2.CascadeClassifier(sec_cascade_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we grab the webcam and configure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing Camera ..\n"
     ]
    }
   ],
   "source": [
    "# Initialize Default Camera\n",
    "webcam = cv2.VideoCapture(0)\n",
    "# Check if Camera initialized correctly\n",
    "success = webcam.isOpened()\n",
    "if success == True:\n",
    "    print('Grabbing Camera ..')\n",
    "        # Uncomment and adjust according to your webcam capabilities\n",
    "        #webcam.set(cv2.CAP_PROP_FPS,30);\n",
    "        #webcam.set(cv2.CAP_PROP_FRAME_WIDTH,1024);\n",
    "        #webcam.set(cv2.CAP_PROP_FRAME_HEIGHT,768);\n",
    "elif success == False:\n",
    "    print('Error: Camera could not be opened')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is a mashup of the video camera test sample_04 and the previous sample_10 for face and eye detection on a still image. Only difference is that it is done on each video frame within the while loop.\n",
    "\n",
    "Video is converted to grayscale and histogram equalization filter is applied to improve the contrast. This helps the Haar Cascade Classifiers. Everything else stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting ...\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    # Read each frame in video stream\n",
    "    ret, frame = webcam.read()\n",
    "    # Perform operations on the frame here\n",
    "    # First convert to Grayscale \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Next run filters\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    # Uncomment for Debug if needed\n",
    "    #cv2.imshow('Grayscale', gray)\n",
    "    # Face detection using Haar Cascades\n",
    "    # Detects objects of different sizes in the input image which are returned as a list of rectangles.\n",
    "    # cv2.CascadeClassifier.detectMultiScale(image[,scaleFactor[,minNeighbors[,flags[,minSize[,maxSize]]]]])\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    # Draw the rectangles around detected Regions of Interest [ROI] - faces\n",
    "    # cv2.rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "    out = frame.copy()\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = out[y:y+h, x:x+w]\n",
    "        # Since eyes are a part of face, limit eye detection to face regions to improve accuracy\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            # Draw the rectangles around detected Regions of Interest [ROI] - eyes\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Facetracker', out)\n",
    "    # Wait for Esc Key to quit\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        print('Quitting ...')\n",
    "        break\n",
    "# Release all resources used\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
